<!DOCTYPE html>
<html>
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    

    <title>
      Reinforcement Learning笔记1-MDP | H.J.T. Github 
    </title>

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    
      <meta name="author" content="H.J.T.">
    
    

    <meta name="description" content="1. 马尔可夫模型介绍（Markov）马尔可夫模型的几类子模型:



　
不考虑动作
考虑动作




状态完全可见
马尔科夫链(MC)
马尔可夫决策过程(MDP)


状态不完全可见
隐马尔可夫模型(HMM)
不完全可观察马尔可夫决策过程(POMDP)




Markdown table - tablesgenerator 

2. 马尔可夫决策过程（MDP）马尔可夫决策过程（Markov">
<meta property="og:type" content="article">
<meta property="og:title" content="Reinforcement Learning笔记1-MDP | H.J.T. Github">
<meta property="og:url" content="http://yoursite.com/2017/11/11/zh-Reinforcement-Learning笔记1-MDP/zh/index.html">
<meta property="og:site_name" content="H.J.T. Github">
<meta property="og:description" content="1. 马尔可夫模型介绍（Markov）马尔可夫模型的几类子模型:



　
不考虑动作
考虑动作




状态完全可见
马尔科夫链(MC)
马尔可夫决策过程(MDP)


状态不完全可见
隐马尔可夫模型(HMM)
不完全可观察马尔可夫决策过程(POMDP)




Markdown table - tablesgenerator 

2. 马尔可夫决策过程（MDP）马尔可夫决策过程（Markov">
<meta property="og:updated_time" content="2017-10-25T13:31:50.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Reinforcement Learning笔记1-MDP | H.J.T. Github">
<meta name="twitter:description" content="1. 马尔可夫模型介绍（Markov）马尔可夫模型的几类子模型:



　
不考虑动作
考虑动作




状态完全可见
马尔科夫链(MC)
马尔可夫决策过程(MDP)


状态不完全可见
隐马尔可夫模型(HMM)
不完全可观察马尔可夫决策过程(POMDP)




Markdown table - tablesgenerator 

2. 马尔可夫决策过程（MDP）马尔可夫决策过程（Markov">
    
    
    
      <link rel="icon" type="image/x-icon" href="/favicon-black-55.png">
    
    <link rel="stylesheet" href="/css/uno.css">
    <link rel="stylesheet" href="/css/highlight.css">
    <link rel="stylesheet" href="/css/archive.css">
    <link rel="stylesheet" href="/css/china-social-icon.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>
<body>

    <!-- hexo-inject:begin --><!-- hexo-inject:end --><span class="mobile btn-mobile-menu">
        <i class="icon icon-list btn-mobile-menu__icon"></i>
        <i class="icon icon-x-circle btn-mobile-close__icon hidden"></i>
    </span>

    

<header class="panel-cover panel-cover--collapsed">


  <div class="panel-main">

  
    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        

        <h1 class="panel-cover__title panel-title"><a href="/" title="link to homepage">H.J.T. Github</a></h1>
        <hr class="panel-cover__divider" />

        

        <div class="navigation-wrapper">

          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">

              
                
                <li class="navigation__item"><a href="/#blog" title="" class="blog-button">首页</a></li>
              
                
                <li class="navigation__item"><a href="/About" title="" class="">关于</a></li>
              
                
                <li class="navigation__item"><a href="/Archive" title="" class="">归档</a></li>
              

            </ul>
          </nav>

          <!-- ----------------------------
To add a new social icon simply duplicate one of the list items from below
and change the class in the <i> tag to match the desired social network
and then add your link to the <a>. Here is a full list of social network
classes that you can use:

    icon-social-500px
    icon-social-behance
    icon-social-delicious
    icon-social-designer-news
    icon-social-deviant-art
    icon-social-digg
    icon-social-dribbble
    icon-social-facebook
    icon-social-flickr
    icon-social-forrst
    icon-social-foursquare
    icon-social-github
    icon-social-google-plus
    icon-social-hi5
    icon-social-instagram
    icon-social-lastfm
    icon-social-linkedin
    icon-social-medium
    icon-social-myspace
    icon-social-path
    icon-social-pinterest
    icon-social-rdio
    icon-social-reddit
    icon-social-skype
    icon-social-spotify
    icon-social-stack-overflow
    icon-social-steam
    icon-social-stumbleupon
    icon-social-treehouse
    icon-social-tumblr
    icon-social-twitter
    icon-social-vimeo
    icon-social-xbox
    icon-social-yelp
    icon-social-youtube
    icon-social-zerply
    icon-mail

-------------------------------->

<!-- add social info here -->



<nav class="cover-navigation navigation--social">
  <ul class="navigation">

    
      <!-- Github -->
      <li class="navigation__item">
        <a href="https://github.com/hjtso" title="Huno on GitHub">
          <i class='icon icon-social-github'></i>
          <span class="label">GitHub</span>
        </a>
      </li>
    

      <!-- Facebook -->
      <li class="navigation__item">
        <a href="https://www.facebook.com/jintao.huang.1" title=“Facebook”>
          <i class='icon icon-social-facebook'></i>
          <span class="label">Facebook</span>
        </a>
      </li>

      <!-- Instagram -->
      <li class="navigation__item">
        <a href="https://www.instagram.com/huang_jintao/" title=“Instagram”>
          <i class='icon icon-social-instagram'></i>
          <span class="label">Instagram</span>
        </a>
      </li>

      <!-- Linkedin -->
      <li class="navigation__item">
        <a href="https://www.linkedin.com/in/jintao-huang-48429565" title=“Linkedin”>
          <i class='icon icon-social-linkedin'></i>
          <span class="label">Linkedin</span>
        </a>
      </li>
    

    <!-- China social icon -->

      <li class="navigation__item">
        <a href="http://www.weibo.com/musimusi" title=“Weibo”>
          <i class='icon cs-icon-weibo'></i>
          <span class="label">Weibo</span>
        </a>
      </li>

    <!--
      <li class="navigation__item">
        <a href="https://www.hjt.so" title=“HJT347341”>
          <i class='icon cs-icon-wechat'></i>
          <span class="label">Wechat</span>
        </a>
      </li>


      <li class="navigation__item">
        <a href="" title="">
          <i class='icon cs-icon-douban'></i>
          <span class="label">Douban</span>
        </a>
      </li>
    -->


  </ul>
</nav>



        </div>

      </div>

    </div>

    <div class="panel-cover--overlay"></div>
  </div>
</header>

    <div class="content-wrapper">
        <div class="content-wrapper__inner entry">
            

<article class="post-container post-container--single">

  <header class="post-header">
    
    <h1 class="post-title">Reinforcement Learning笔记1-MDP</h1>

    

    <div class="post-meta">
      <time datetime="2017-11-11" class="post-meta__date date">2017-11-11</time> 

      <span class="post-meta__tags tags">

          

          

      </span>
    </div>
    
    

  </header>

  <section id="post-content" class="article-content post">
    <h3 id="1-马尔可夫模型介绍（Markov）"><a href="#1-马尔可夫模型介绍（Markov）" class="headerlink" title="1. 马尔可夫模型介绍（Markov）"></a>1. 马尔可夫模型介绍（Markov）</h3><p>马尔可夫模型的几类子模型:</p>
<table>
<thead>
<tr>
<th>　</th>
<th style="text-align:center">不考虑动作</th>
<th style="text-align:center">考虑动作</th>
</tr>
</thead>
<tbody>
<tr>
<td>状态完全可见</td>
<td style="text-align:center">马尔科夫链(MC)</td>
<td style="text-align:center">马尔可夫决策过程(MDP)</td>
</tr>
<tr>
<td>状态不完全可见</td>
<td style="text-align:center">隐马尔可夫模型(HMM)</td>
<td style="text-align:center">不完全可观察马尔可夫决策过程(POMDP)</td>
</tr>
</tbody>
</table>
<ul>
<li>Markdown table - <a href="http://www.tablesgenerator.com/markdown_tables" title="Title" target="_blank" rel="external">tablesgenerator</a> </li>
</ul>
<h3 id="2-马尔可夫决策过程（MDP）"><a href="#2-马尔可夫决策过程（MDP）" class="headerlink" title="2. 马尔可夫决策过程（MDP）"></a>2. 马尔可夫决策过程（MDP）</h3><p>马尔可夫决策过程（Markov Decision Processes, MDP）简单说就是一个智能体（Agent）采取行动（Action）从而改变自己的状态（State）获得奖励（Reward）与环境（Environment）发生交互的循环过程。</p>
<p>MDP 的策略完全取决于当前状态（Only present matters），可以简单表示为： </p>
<p>M = <s, a,="" p_{s,a},="" r=""></s,></p>
<p> ① $s \in S$: 有限状态 state 集合，s 表示某个特定状态</p>
<p> ② $a \in A$: 有限动作 action 集合，a 表示某个特定动作</p>
<p> ③ Transition Model $T(S, a, S’) \sim P_r(s’|s, a)$: Transition Model, 根据当前状态 s 和动作 a 预测下一个状态 $s’$，这里的 $P_r$ 表示从 s 采取行动 a 转移到 $s’$ 的概率</p>
<p> ④ Reward $R(s, a) = E[R_{t+1}|s, a]$:表示 agent 采取某个动作后的即时奖励，它还有 R(s, a, s’), R(s) 等表现形式，采用不同的形式，其意义略有不同</p>
<p> ⑤ Policy $\pi(s) \to a$: 根据当前 state 来产生 action，可表现为 $a=\pi(s)$ 或 $\pi(a|s) = P[a|s]$，后者表示某种状态下执行某个动作的概率</p>
<h3 id="3-回报"><a href="#3-回报" class="headerlink" title="3. 回报"></a>3. 回报</h3><p>U(s0,s1,s2…) 与 折扣率（discount）y: U 代表执行一组 action 后所有状态累计的 reward 之和，但由于直接的 reward 相加在无限时间序列中会导致无偏向，而且会产生状态的无限循环。因此在这个 Utility 函数里引入 y 折扣率这一概念，令往后的状态所反馈回来的 reward 乘上这个 discount 系数，这样意味着当下的 reward 比未来反馈的 reward 更重要，这也比较符合直觉。定义：</p>
<p>\begin{align}<br>U(s_0\,s_1\,s_2\,\cdots) &amp;= \sum_{t=0}^{\infty}{\gamma^tR(s_t)} \quad 0\le\gamma&lt;1 \\<br>    &amp;\le \sum_{t=0}^{\infty }{\gamma^tR_{max}} = \frac{R_{max}}{1-\gamma}<br>\end{align}</p>
<p>由于引入了 discount，可以看到我们把一个无限长度的问题转换成了一个拥有最大值上限的问题。</p>
<p>强化学习的目的是最大化长期未来奖励，即寻找最大的 U。</p>
<p>于回报（return），再引入两个函数：</p>
<p> ① 状态价值函数：</p>
<p>\begin{align}<br> v(s)=E[U_t|S_t=s]<br>\end{align}</p>
<p> 意义为基于 t 时刻的状态 s 能获得的未来回报（return）的期望，加入动作选择策略后可表示为 </p>
<p>\begin{align}<br> v_{\pi}(s)=E_{\pi}<a href="U_t=R_{t+1}+\gamma R_{t+2}+\cdots+\gamma^{T-t-1}R_T">U_t|S_t=s</a><br>\end{align}</p>
<p> ② 动作价值函数：</p>
<p>\begin{align}<br> q_{\pi}=E_{\pi}[U_t|S_t=s,\,A_t=a]<br>\end{align}</p>
<p>意义为基于 t 时刻的状态 s，选择一个 action 后能获得的未来回报（return）的期望。</p>
<ul>
<li>价值函数用来衡量某一状态或动作-状态的优劣，即对智能体来说是否值得选择某一状态或在某一状态下执行某一动作</li>
</ul>
<h3 id="4-MDP-求解"><a href="#4-MDP-求解" class="headerlink" title="4. MDP 求解"></a>4. MDP 求解</h3><p>需要找到最优的策略使未来回报最大化，求解过程大致可分为两步：</p>
<p> ① 预测：给定策略，评估相应的状态价值函数和状态-动作价值函数</p>
<p> ② 行动：根据价值函数得到当前状态对应的最优动作</p>
<ul>
<li>推荐课程 - <a href="http://rll.berkeley.edu/deeprlcourse/" title="Title" target="_blank" rel="external">CS 294: Deep Reinforcement Learning</a></li>
</ul>
<h3 id="参考资料（Reference）"><a href="#参考资料（Reference）" class="headerlink" title="参考资料（Reference）"></a>参考资料（Reference）</h3><ul>
<li><p><a href="https://mpatacchiola.github.io/blog/2016/12/09/dissecting-reinforcement-learning.html" title="Title" target="_blank" rel="external">Dissecting Reinforcement Learning-Part.1</a> </p>
</li>
<li><p><a href="https://studywolf.wordpress.com/2012/11/25/reinforcement-learning-q-learning-and-exploration/" title="Title" target="_blank" rel="external">REINFORCEMENT LEARNING PART 1: Q-LEARNING AND EXPLORATION</a> </p>
</li>
<li><p><a href="https://qiita.com/Hironsan/items/56f6c0b2f4cfd28dd906" title="Title" target="_blank" rel="external">Pythonではじめる強化学習</a> </p>
</li>
<li><p><a href="https://qiita.com/icoxfog417/items/242439ecd1a477ece312" title="Title" target="_blank" rel="external">ゼロからDeepまで学ぶ強化学習</a> </p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/25319023?utm_source=tuicool&amp;utm_medium=referral" title="Title" target="_blank" rel="external">强化学习知识整理</a> </p>
</li>
</ul>

  </section>

  
  
</article>


            <footer class="footer">

    <span class="footer__copyright">&copy; 2014-2015. | 由<a href="https://hexo.io/">Hexo</a>强力驱动 | 主题<a href="https://github.com/someus/huno">Huno</a></span>
    
</footer>
        </div>
    </div>

    <!-- js files -->
    <script src="/js/jquery.min.js"></script>
    <script src="/js/main.js"></script>
    <script src="/js/scale.fix.js"></script>
    

    

    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript"> 
        $(document).ready(function(){
            MathJax.Hub.Config({ 
                tex2jax: {inlineMath: [['[latex]','[/latex]'], ['\\(','\\)']]} 
            });
        });
    </script>


    

    <script src="/js/awesome-toc.min.js"></script>
    <script>
        $(document).ready(function(){
            $.awesome_toc({
                overlay: true,
                contentId: "post-content",
            });
        });
    </script>


    
    
    <!--kill ie6 -->
<!--[if IE 6]>
  <script src="//letskillie6.googlecode.com/svn/trunk/2/zh_CN.js"></script>
<![endif]--><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
